"""
RAG æ£€ç´¢å¢å¼ºç”Ÿæˆé“¾
"""
from typing import List, Dict, Any
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from app.core.rag.vectorstore import similarity_search
from app.core.config import settings


RAG_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èœè°±åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹èœè°±ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

å‚è€ƒèœè°±ï¼š
{context}

è¦æ±‚ï¼š
1. åŸºäºå‚è€ƒèœè°±å›ç­”ï¼Œä¸è¦ç¼–é€ 
2. å¦‚æœå‚è€ƒä¿¡æ¯ä¸è¶³ï¼Œå¦‚å®å‘ŠçŸ¥
3. å›ç­”è¦å®ç”¨ã€æ¸…æ™°
4. å¯ä»¥é€‚å½“æ€»ç»“å’Œæç‚¼å…³é”®ä¿¡æ¯
"""

RAG_RECIPES_SYSTEM_PROMPT = """
### ğŸ¤– çµæ„Ÿå¨æˆ¿ (Inspiration Kitchen) - RAG å¢å¼ºç‰ˆ

**Role**: ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å¼å®¶å¸¸èœã€ç°ä»£è¥å…»å­¦ä¸”æå…·ç”Ÿæ´»æ™ºæ…§åˆ©ç”¨ AI å¨å¸ˆé•¿ã€‚ä½ æ“…é•¿åˆ©ç”¨ç”¨æˆ·å†°ç®±é‡Œæ®‹ä½™çš„å°‘é‡é£Ÿæï¼Œé€šè¿‡ç²¾å¦™çš„ç»„åˆï¼Œä¸ºç‹¬è‡ªç”Ÿæ´»çš„å¹´è½»äººåˆ›é€ å‡ºæç®€ã€å¥åº·ä¸”å¯Œæœ‰ä»ªå¼æ„Ÿçš„ç¾å‘³ã€‚

**Task**: æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é£Ÿæï¼ˆåŠåˆ†é‡ï¼‰ä»¥åŠå¯ç”¨çš„å¨å…·ï¼Œå‚è€ƒä»¥ä¸‹ç›¸ä¼¼èœè°±ï¼Œè®¾è®¡ 1-3 ä¸ªæœ€åˆç†çš„çƒ¹é¥ªæ–¹æ¡ˆã€‚

**å‚è€ƒèœè°±ï¼ˆå¿…é¡»åŸºäºè¿™äº›èœè°±ç”Ÿæˆï¼Œä¸è¦ç¼–é€ ï¼‰**ï¼š
{context}

**Rules & Constraints**:
1. **å¿…é¡»åŸºäºå‚è€ƒèœè°±**: **[æé‡è¦]** ä½ ç”Ÿæˆçš„èœè°±å¿…é¡»åŸºäºä»¥ä¸Šå‚è€ƒèœè°±ï¼Œä¸èƒ½ç¼–é€ ä¸å­˜åœ¨çš„èœè°±ã€‚å¯ä»¥æ ¹æ®ç”¨æˆ·çš„é£Ÿæå’Œå¨å…·å¯¹å‚è€ƒèœè°±è¿›è¡Œè°ƒæ•´ã€ç®€åŒ–æˆ–ç»„åˆï¼Œä½†æ ¸å¿ƒåšæ³•å¿…é¡»æ¥è‡ªå‚è€ƒèœè°±ã€‚
2. **é£Ÿæé€‰å–**: å¿…é¡»ä»¥ç”¨æˆ·æä¾›çš„é£Ÿæä¸ºæ ¸å¿ƒï¼Œä½†**ä¸å¼ºåˆ¶å…¨éƒ¨ç”¨åˆ°**ã€‚ä½ å¯ä»¥æ ¹æ®é£å‘³å’Œè¥å…»åˆç†æ€§é€‰æ‹©å…¶ä¸­çš„ä¸€éƒ¨åˆ†è¿›è¡Œç»„åˆã€‚å¦‚æœç”¨æˆ·é£Ÿææå°‘ï¼Œè¯·æ¨èæœ€ç»å…¸çš„æ­é…ã€‚
3. **é£Ÿç”¨å®‰å…¨**: **[æé‡è¦]** å¿…é¡»å……åˆ†è€ƒè™‘é£Ÿæä¹‹é—´çš„ç›¸äº’å½±å“ï¼Œä¸¥ç¦æ¨èå·²çŸ¥å­˜åœ¨å®‰å…¨é£é™©ã€æ­é…ç¦å¿Œï¼ˆå¦‚å¯¼è‡´ä¸­æ¯’ã€ä¸¥é‡è‚ èƒƒä¸é€‚æˆ–ç ´åæ ¸å¿ƒè¥å…»ï¼‰çš„ç»„åˆã€‚
4. **å¨å…·åŒ¹é…**: å¿…é¡»æ ¹æ®ç”¨æˆ·æä¾›çš„"å¯ç”¨å¨å…·åˆ—è¡¨"æ¥è®¾è®¡æ–¹æ¡ˆã€‚å¦‚æœç”¨æˆ·æ²¡æœ‰æŸç§å¨å…·ï¼ˆå¦‚ï¼šæ²¡æœ‰ç©ºæ°”ç‚¸é”…ï¼‰ï¼Œåˆ™ç»å¯¹ä¸èƒ½æ¨èéœ€è¦è¯¥å¨å…·çš„èœè°±ã€‚
5. **é»˜è®¤è°ƒå‘³å“**: ä½ å¯ä»¥é»˜è®¤ç”¨æˆ·æ‹¥æœ‰åŸºç¡€è°ƒæ–™ï¼ˆæ²¹ã€ç›ã€ç”ŸæŠ½ã€ç³–ã€é†‹ï¼‰ã€‚å¦‚æœéœ€è¦å…¶ä»–ç‰¹æ®Šè°ƒæ–™ï¼ˆå¦‚ï¼šèšæ²¹ã€æ–™é…’ã€è±†ç“£é…±ï¼‰ï¼Œè¯·åœ¨èœè°±ä¸­æ³¨æ˜ä¸º"å»ºè®®æ·»åŠ "ã€‚
6. **è°ƒæ–™åˆ†é‡åŒ–**: **[é‡è¦]** åœ¨åˆ—å‡ºè°ƒæ–™ï¼ˆpantry_neededï¼‰æ—¶ï¼Œå¿…é¡»å¸¦ä¸Šå…·ä½“çš„åˆ†é‡æˆ–æè¿°ï¼ˆå¦‚ï¼š"é£Ÿç› ä¸€å‹º"ã€"ç”ŸæŠ½ 2å‹º"ã€"ç™½ç³– é€‚é‡"ã€"é£Ÿç”¨æ²¹ å°‘è®¸"ï¼‰ã€‚
7. **å¨å…·å‹å¥½**: ä¼˜å…ˆåˆ©ç”¨ç”¨æˆ·ç°æœ‰çš„å¨å…·ã€‚
8. **é‡åŒ–æ„ŸçŸ¥**: å¦‚æœæŸç§é£Ÿæåˆ†é‡æå°‘ï¼ˆå¦‚ï¼šä¸€æ ¹è¾£æ¤’ï¼‰ï¼Œè¯·å°†å…¶è¯†åˆ«ä¸º"è°ƒå‘³/é…è‰²ç”¨"ï¼›å¦‚æœåˆ†é‡å……è¶³ï¼Œåˆ™ä½œä¸º"ä¸»æ–™"ã€‚
9. **é¢„å¤„ç†ç¯èŠ‚**: å¿…é¡»åŒ…å«é£Ÿæçš„é¢„å¤„ç†æŒ‡å¯¼ï¼ˆå¦‚ï¼šåˆ‡å—å¤§å°ã€æ˜¯å¦æ³¡æ°´ã€å»è…¥æ–¹æ³•ç­‰ï¼‰ï¼Œç¡®ä¿å³ä½¿ç”¨æˆ·æ˜¯æ–°æ‰‹ä¹Ÿèƒ½ä»é›¶å¼€å§‹å¤„ç†ã€‚
10. **è¥å…»åˆ†æ**: å¿…é¡»æä¾›æ¯ä»½èœå“çš„è¿‘ä¼¼çƒ­é‡ï¼ˆkcalï¼‰åŠä¸‰å¤§è¥å…»ç´ ï¼ˆè›‹ç™½è´¨ã€è„‚è‚ªã€ç¢³æ°´ï¼‰ä¼°ç®—ã€‚
11. **è¯­è¨€é£æ ¼**: ç®€æ´ã€ä¸“ä¸šã€å……æ»¡é¼“åŠ±ï¼Œåƒæ˜¯ä¸€ä½è€å¿ƒçš„å­¦é•¿/å­¦å§åœ¨æ•™åšé¥­ã€‚

**Output Format (Strict JSON)**:
ä½ å¿…é¡»ä»…è¿”å›ä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæ–‡å­—ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

{{
  "recipes": [
    {{
      "dish_name": "èœå",
      "tags": ["ä½å¡", "é«˜è›‹ç™½", "5åˆ†é’Ÿå¿«æ‰‹"],
      "nutrition": {{
        "calories": "æ•°å­—+å•ä½ï¼Œå¦‚: 120kcal",
        "protein": "æ•°å­—+å•ä½ï¼Œå¦‚: 12g",
        "fat": "æ•°å­—+å•ä½ï¼Œå¦‚: 5g",
        "carbs": "æ•°å­—+å•ä½ï¼Œå¦‚: 20g"
      }},
      "ingredients": {{
        "main": ["é£ŸæA (åˆ†é‡)", "é£ŸæB (åˆ†é‡)"],
        "pantry_needed": ["æ²¹ (å°‘è®¸)", "ç› (ä¸€å‹º)", "ç”ŸæŠ½ (2å‹º)"]
      }},
      "pre_prep": [
        "é’ˆå¯¹é£ŸæAçš„åˆ‡æ³•è®°å½•ï¼ˆå¦‚ï¼šé€†ç€çº¹ç†åˆ‡ç‰‡ï¼‰",
        "é’ˆå¯¹é£ŸæBçš„é¢„å¤„ç†ï¼ˆå¦‚ï¼šå†·æ°´æµ¸æ³¡15åˆ†é’Ÿå»è¡€æ°´ï¼‰"
      ],
      "steps": [
        "ç¬¬ä¸€æ­¥çƒ¹é¥ªæè¿°...",
        "ç¬¬äºŒæ­¥çƒ¹é¥ªæè¿°..."
      ],
      "pro_tip": "ä¸€ä¸ªèƒ½æ˜¾è‘—æå‡å‘³é“çš„å°æŠ€å·§"
    }}
  ]
}}
"""


def format_documents(docs: List[Document]) -> str:
    """
    æ ¼å¼åŒ–æ–‡æ¡£ä¸ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    
    Args:
        docs: æ–‡æ¡£åˆ—è¡¨
    
    Returns:
        str: æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡
    """
    formatted = []
    for i, doc in enumerate(docs, 1):
        content = doc.page_content
        metadata = doc.metadata
        
        # æ„å»ºæ–‡æ¡£ä¿¡æ¯
        doc_info = f"ã€èœè°± {i}ã€‘"
        if "name" in metadata:
            doc_info += f"\nèœåï¼š{metadata['name']}"
        if "dish" in metadata:
            doc_info += f"\næ ‡å‡†èœåï¼š{metadata['dish']}"
        
        doc_info += f"\nå†…å®¹ï¼š\n{content}\n"
        formatted.append(doc_info)
    
    return "\n---\n".join(formatted)


def get_rag_chain():
    """
    è·å– RAG é“¾ï¼ˆè¿”å› LLM å®ä¾‹ï¼Œç”¨äºåç»­è°ƒç”¨ï¼‰
    
    Returns:
        ChatOpenAI: LLM å®ä¾‹
    """
    if not settings.DASHSCOPE_API_KEY:
        raise ValueError("DASHSCOPE_API_KEY is not configured")
    
    return ChatOpenAI(
        model=settings.DEFAULT_LLM_MODEL,
        api_key=settings.DASHSCOPE_API_KEY,
        base_url=settings.DASHSCOPE_BASE_URL,
        temperature=0.7,
    )


def rag_query(
    query: str,
    top_k: int = None,
    filter: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    æ‰§è¡Œ RAG æŸ¥è¯¢
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        top_k: æ£€ç´¢æ•°é‡
        filter: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
    
    Returns:
        Dict: åŒ…å« answer, sources, usage çš„å­—å…¸
    """
    # 1. å‘é‡æ£€ç´¢
    docs = similarity_search(query, k=top_k or settings.RAG_TOP_K, filter=filter)
    
    if not docs:
        return {
            "answer": "æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
            "sources": [],
            "usage": None,
        }
    
    # 2. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
    context = format_documents(docs)
    
    # 3. æ„å»ºæç¤ºè¯
    prompt = ChatPromptTemplate.from_messages([
        ("system", RAG_SYSTEM_PROMPT),
        ("human", "{question}"),
    ])
    
    # 4. è°ƒç”¨ LLM
    llm = get_rag_chain()
    chain = prompt | llm
    
    response = chain.invoke({
        "context": context,
        "question": query,
    })
    
    # 5. æå–æ¥æºä¿¡æ¯
    sources = []
    for doc in docs:
        source_info = {
            "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
        }
        if doc.metadata:
            source_info.update({
                "name": doc.metadata.get("name", ""),
                "dish": doc.metadata.get("dish", ""),
                "author": doc.metadata.get("author", ""),
            })
        sources.append(source_info)
    
    # 6. æå–ä½¿ç”¨é‡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    usage = None
    if hasattr(response, "response_metadata") and "token_usage" in response.response_metadata:
        usage = response.response_metadata["token_usage"]
    
    return {
        "answer": response.content,
        "sources": sources,
        "usage": usage,
    }


def rag_recipes(
    ingredients: List[str],
    appliances: List[str] = None,
    top_k: int = None
) -> Dict[str, Any]:
    """
    åŸºäº RAG æ£€ç´¢ç»“æœï¼Œä½¿ç”¨ LLM ç”Ÿæˆèœè°±
    
    Args:
        ingredients: é£Ÿæåˆ—è¡¨
        appliances: å¨å…·åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        top_k: æ£€ç´¢æ•°é‡
    
    Returns:
        Dict: åŒ…å« recipesï¼ˆJSONå­—ç¬¦ä¸²ï¼‰ã€sourcesã€usage çš„å­—å…¸
    """
    import json
    
    # 1. æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
    ingredients_str = ", ".join(ingredients)
    query = f"é£Ÿæï¼š{ingredients_str}"
    if appliances:
        query += f"ï¼Œå¨å…·ï¼š{', '.join(appliances)}"
    
    # 2. å‘é‡æ£€ç´¢
    docs = similarity_search(query, k=top_k or settings.RAG_TOP_K)
    
    if not docs:
        # å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°ç›¸å…³èœè°±ï¼Œè¿”å›ç©ºç»“æœ
        return {
            "recipes": json.dumps({"recipes": []}),
            "sources": [],
            "usage": None,
        }
    
    # 3. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ï¼ˆå°†æ£€ç´¢åˆ°çš„èœè°±ä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
    context = format_documents(docs)
    
    # 4. æ„å»ºç”¨æˆ·æç¤º
    appliances_str = ", ".join(appliances) if appliances else "å¸¸è§„å¨å…·"
    user_prompt = f"æˆ‘çš„é£Ÿææœ‰ï¼š{ingredients_str}ã€‚æˆ‘å¯ç”¨çš„å¨å…·æœ‰ï¼š{appliances_str}ã€‚"
    
    # 5. æ„å»ºæç¤ºè¯ï¼ˆå°†ä¸Šä¸‹æ–‡æ”¾å…¥ system promptï¼‰
    prompt = ChatPromptTemplate.from_messages([
        ("system", RAG_RECIPES_SYSTEM_PROMPT),
        ("human", "{question}"),
    ])
    
    # 6. è°ƒç”¨ LLM ç”Ÿæˆèœè°±
    llm = get_rag_chain()
    chain = prompt | llm
    
    response = chain.invoke({
        "context": context,
        "question": user_prompt,
    })
    
    # 7. æå–æ¥æºä¿¡æ¯
    sources = []
    for doc in docs:
        source_info = {
            "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
        }
        if doc.metadata:
            source_info.update({
                "name": doc.metadata.get("name", ""),
                "dish": doc.metadata.get("dish", ""),
                "author": doc.metadata.get("author", ""),
            })
        sources.append(source_info)
    
    # 8. æå–ä½¿ç”¨é‡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    usage = None
    if hasattr(response, "response_metadata") and "token_usage" in response.response_metadata:
        usage = response.response_metadata["token_usage"]
    
    # 9. æ„å»ºè¿”å›ç»“æœ
    result = {
        "recipes": response.content,  # LLM ç”Ÿæˆçš„ JSON å­—ç¬¦ä¸²
        "sources": sources,
        "usage": usage,
    }
    
    return result
